{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches the AWS model as first pass\n",
    "\n",
    "class OnlineBinPackingEnv(gym.Env):\n",
    "    '''\n",
    "    Online Bin Packing Problem\n",
    "\n",
    "    The Bin Packing Problem (BPP) is a combinatorial optimization problem which\n",
    "    requires the user to select from a range of goods of different values and\n",
    "    weights in order to maximize the value of the selected items within a \n",
    "    given weight limit. This version is online meaning each item is randonly\n",
    "    presented to the algorithm one at a time, at which point the algorithm \n",
    "    can either accept or reject the item. After seeing a fixed number of \n",
    "    items are shown, the episode terminates. If the weight limit is reached\n",
    "    before the episode ends, then it terminates early.\n",
    "\n",
    "    Observation:\n",
    "        Type: Tuple, Discrete\n",
    "        0 - bin_capacity: Count of bins at a given level h\n",
    "        -1: Current item size\n",
    "\n",
    "\n",
    "    Actions:\n",
    "        Type: Discrete\n",
    "        0: Open a new bin and place item into bin\n",
    "        1+: Attempt to place item into bin at the given level\n",
    "\n",
    "    Reward:\n",
    "        Negative of the waste, which is the difference between the current\n",
    "        size and excess space of the bin.\n",
    "\n",
    "    Starting State:\n",
    "        No available bins and random starting item\n",
    "        \n",
    "    Episode Termination:\n",
    "        When invalid action is selected (e.g. attempt to place item in non-existent\n",
    "        bin), bin limits are exceeded, or step limit is reached.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.bin_capacity = 9\n",
    "        self.item_sizes = [2, 3]\n",
    "        self.item_probs = [0.8, 0.2]\n",
    "        self.step_counter = 0\n",
    "        self.step_limit = 1000\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0] * (1 + self.bin_capacity)),\n",
    "            high=np.array([self.step_limit] * self.bin_capacity + [max(self.item_sizes)]),\n",
    "            dtype=np.uint32)\n",
    "        \n",
    "        self.action_space = spaces.Discrete(self.bin_capacity)\n",
    "        \n",
    "        self.seed()\n",
    "        self.state = self.reset()\n",
    "        \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        if action >= self.bin_capacity:\n",
    "            raise ValueError('{} is an invalid action. Must be between {} and {}'.format(\n",
    "                action, 0, self.bin_capacity))\n",
    "        elif action > (self.bin_capacity - self.item_size):\n",
    "            # Bin overflows\n",
    "            reward = BIG_NEG_REWARD - self.waste\n",
    "            done = True\n",
    "        elif action == 0:\n",
    "            # Create new bin\n",
    "            self.bin_levels[self.item_size] += 1\n",
    "            # This waste penalty seems very strange, it only occurs\n",
    "            # when a new bin is opened.\n",
    "            self.waste = self.bin_capacity - self.item_size\n",
    "            reward = -1 * self.waste\n",
    "        elif self.bin_levels[action] == 0:\n",
    "            # Can't insert item into non-existent bin\n",
    "            reward = BIG_NEG_REWARD - self.waste\n",
    "            done = True\n",
    "        else:\n",
    "            if action + self.item_size == self.bin_capacity:\n",
    "                self.num_full_bins += 1\n",
    "            else:\n",
    "                self.bin_levels[action + self.item_size] += 1\n",
    "            self.waste = -self.item_size\n",
    "            reward = -1 * self.waste\n",
    "            \n",
    "            self.bin_levels[action] -= 1\n",
    "        \n",
    "        self.total_reward += reward\n",
    "        \n",
    "        if self.step_counter >= self.step_limit:\n",
    "            done = True\n",
    "            \n",
    "        if self.step_counter == self.step_limit:\n",
    "            done = True\n",
    "            \n",
    "        self.item_size = self.get_item()\n",
    "        state = self.bin_levels + [self.item_size]\n",
    "        \n",
    "        return self.state, reward, done, {}\n",
    "    \n",
    "    def get_item(self):\n",
    "        return np.random.choice(self.item_sizes, p=self.item_probs)\n",
    "        \n",
    "    def sample_action(self):\n",
    "        return self.action_space.sample()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_weight = 0\n",
    "        self.step_counter = 0        \n",
    "        self.num_full_bins = 0\n",
    "        self.total_reward = 0\n",
    "        self.waste = 0\n",
    "        self.step_counter = 0\n",
    "        \n",
    "        self.bin_levels = [0] * self.bin_capacity\n",
    "        self.item_size = self.get_item()\n",
    "        initial_state = self.bin_levels + [self.item_size]\n",
    "        return initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Bin Packing\n",
    "\n",
    "A random sequence of items $i$ with size $w_i \\in W_i$, is provided to an algorithm to be packed into various bins $B$ denoted by $j \\in J$, where the capacity of each bin is given by $\\textrm{max}(W_i) \\leq B_j^{max} < \\infty \\; \\forall j \\in J$. Each item $i$ arrives at a given time $t \\in T$, and is sampled according to a fixed probability $p_i$. Following Gupta and Radovanovic, we assume all bin and item sizes are integer values.\n",
    "\n",
    "## Amazon Implementation\n",
    "\n",
    "Unlimited bins, each with identical capacity. Assign to group of bins based on level $h$, whereby $N_h(t)$ is the number of bins at that level. The action, $a_t$ is to select the level to assign the item to, or, in the case of $a_t=0$, to open a new, empty bin. $R_t$ is the negative of the incremental waste as $i$ is assigned to $B_j$. They use an action mask to prevent infeasible actions.\n",
    "\n",
    "They proivde a large negative reward (-100) for any actions that prematurely end the episode. Additionally, the reward function seems odd as implemented by the AWS team. In the [original paper](https://arxiv.org/pdf/1211.2687.pdf), it is given as:\n",
    "\n",
    "$$W_F(n) = \\sum_{h=1}^{B-1} N_h(n)(B-h)$$\n",
    "\n",
    "where $W_F(n)$ is the total accumulated empty space in partially filled bins after n items from the distribution $F$ have been packed by the algorithm. The AWS implementation returns $B-h$ for every new bin created, a positive reward if it does fit in an existing bin, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
